{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17800,"status":"ok","timestamp":1716333419663,"user":{"displayName":"박태우","userId":"12492517778931241346"},"user_tz":-540},"id":"xV7z-yIHva2K","outputId":"9ab71154-fefb-4215-99ea-daa394b1cfc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"ECxNcYjjUaKH"},"source":["#데이터 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4nI_ceMCZw0N"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense, Reshape, SeparableConv2D, Conv2D, BatchNormalization, Multiply, Layer,Attention, LayerNormalization, Add\n","from tensorflow.keras.applications import MobileNet\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1621,"status":"ok","timestamp":1716355884515,"user":{"displayName":"박태우","userId":"12492517778931241346"},"user_tz":-540},"id":"0C-5LhNHJapI","outputId":"6fa4d4fa-3ca3-440f-e857-31a1596f6059"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5853 images belonging to 4 classes.\n","Found 1168 images belonging to 4 classes.\n"]}],"source":["# 데이터 경로\n","train_data_dir = '/content/drive/MyDrive/Data/img/train'\n","validation_data_dir = '/content/drive/MyDrive/Data/img/val'\n","\n","# 데이터 증강\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    brightness_range=[0.8, 1.2]\n",")\n","\n","val_test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# 이미지 불러오기\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","validation_generator = val_test_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"-AyS03TtfQzB"},"source":["#MobileNetV1 기반 모델링(실행환경 T4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQEGryRQVpbb"},"outputs":[],"source":["# Base model 정의\n","def create_base_model(input_shape):\n","    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base_model.trainable = False\n","    return base_model\n","\n","# 패치 추출 레이어 정의\n","def patch_extraction_layer():\n","    return tf.keras.Sequential([\n","        SeparableConv2D(256, kernel_size=4, strides=4, padding='same', activation='relu'),\n","        SeparableConv2D(256, kernel_size=2, strides=2, padding='valid', activation='relu'),\n","        Conv2D(256, kernel_size=1, strides=1, padding='valid', activation='relu')\n","    ], name='patch_extraction')\n","\n","# Pre-classification 레이어 정의\n","def create_pre_classification_layer():\n","    return tf.keras.Sequential([\n","        Dense(32, activation='relu'),\n","        BatchNormalization()\n","    ], name='pre_classification')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1524,"status":"ok","timestamp":1716355886357,"user":{"displayName":"박태우","userId":"12492517778931241346"},"user_tz":-540},"id":"JIGHKPC_X5jp","outputId":"b5e7f2e7-7989-445a-f7bc-67efadeaf58f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," mobilenet_1.00_224 (Functi  (None, 7, 7, 1024)        3228864   \n"," onal)                                                           \n","                                                                 \n"," gap (GlobalAveragePooling2  (None, 1024)              0         \n"," D)                                                              \n","                                                                 \n"," dense_1 (Dense)             (None, 4)                 4100      \n","                                                                 \n","=================================================================\n","Total params: 3232964 (12.33 MB)\n","Trainable params: 4100 (16.02 KB)\n","Non-trainable params: 3228864 (12.32 MB)\n","_________________________________________________________________\n"]}],"source":["def create_mobilenet(input_shape, num_classes):\n","    base_model = create_base_model(input_shape)\n","    inputs = Input(shape=input_shape)\n","    # 기본 모델\n","    x = base_model(inputs, training=False)\n","    # GlobalAveragePooling2D 및 Dropout\n","    x = GlobalAveragePooling2D(name='gap')(x)\n","    # 출력층\n","    outputs = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs, outputs)\n","    return model\n","\n","\n","# 모델 생성 및 컴파일\n","model = create_mobilenet(input_shape=(224, 224, 3), num_classes=4)\n","model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 모델 요약 출력\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQdn9ZuV0CeI"},"outputs":[],"source":["# 학습률 조정 콜백\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, min_delta=0.005, min_lr=1e-7)\n","\n","# EarlyStopping 콜백\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, min_delta=0.005, restore_best_weights=True)\n","\n","# 클래스 가중치 추가\n","train_samples_per_class = np.array([1440, 1489, 1477, 1447])\n","total_train_samples = np.sum(train_samples_per_class)\n","class_weights = {i: total_train_samples / (len(train_samples_per_class) * count) for i, count in enumerate(train_samples_per_class)}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"F9Qda9o00Ex4","outputId":"757b0e3e-8265-45c8-e364-93bc9c281bf0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","183/183 [==============================] - 598s 3s/step - loss: 1.4281 - accuracy: 0.3463 - val_loss: 1.3758 - val_accuracy: 0.3776 - lr: 0.0010\n","Epoch 2/100\n","183/183 [==============================] - 565s 3s/step - loss: 1.2718 - accuracy: 0.4213 - val_loss: 1.2598 - val_accuracy: 0.4349 - lr: 0.0010\n","Epoch 3/100\n","183/183 [==============================] - 566s 3s/step - loss: 1.1965 - accuracy: 0.4731 - val_loss: 1.2317 - val_accuracy: 0.4486 - lr: 0.0010\n","Epoch 4/100\n","183/183 [==============================] - 570s 3s/step - loss: 1.1579 - accuracy: 0.4886 - val_loss: 1.2902 - val_accuracy: 0.4426 - lr: 0.0010\n","Epoch 5/100\n","183/183 [==============================] - 566s 3s/step - loss: 1.1375 - accuracy: 0.5056 - val_loss: 1.2079 - val_accuracy: 0.4632 - lr: 0.0010\n","Epoch 6/100\n","183/183 [==============================] - 573s 3s/step - loss: 1.1196 - accuracy: 0.5155 - val_loss: 1.2152 - val_accuracy: 0.4452 - lr: 0.0010\n","Epoch 7/100\n","183/183 [==============================] - 566s 3s/step - loss: 1.0962 - accuracy: 0.5247 - val_loss: 1.1952 - val_accuracy: 0.4692 - lr: 0.0010\n","Epoch 8/100\n","183/183 [==============================] - 580s 3s/step - loss: 1.0825 - accuracy: 0.5349 - val_loss: 1.2123 - val_accuracy: 0.4623 - lr: 0.0010\n","Epoch 9/100\n","183/183 [==============================] - 566s 3s/step - loss: 1.0824 - accuracy: 0.5372 - val_loss: 1.1865 - val_accuracy: 0.4726 - lr: 0.0010\n","Epoch 10/100\n","183/183 [==============================] - 560s 3s/step - loss: 1.0430 - accuracy: 0.5589 - val_loss: 1.1851 - val_accuracy: 0.4700 - lr: 1.0000e-04\n","Epoch 11/100\n","183/183 [==============================] - 573s 3s/step - loss: 1.0323 - accuracy: 0.5667 - val_loss: 1.1801 - val_accuracy: 0.4846 - lr: 1.0000e-04\n","Epoch 12/100\n","183/183 [==============================] - 569s 3s/step - loss: 1.0363 - accuracy: 0.5686 - val_loss: 1.1807 - val_accuracy: 0.4854 - lr: 1.0000e-04\n","Epoch 13/100\n","183/183 [==============================] - 557s 3s/step - loss: 1.0265 - accuracy: 0.5741 - val_loss: 1.1836 - val_accuracy: 0.4795 - lr: 1.0000e-04\n","Epoch 14/100\n","183/183 [==============================] - 546s 3s/step - loss: 1.0203 - accuracy: 0.5759 - val_loss: 1.1817 - val_accuracy: 0.4760 - lr: 1.0000e-05\n","Epoch 15/100\n","183/183 [==============================] - 555s 3s/step - loss: 1.0290 - accuracy: 0.5691 - val_loss: 1.1808 - val_accuracy: 0.4786 - lr: 1.0000e-05\n","Epoch 16/100\n","183/183 [==============================] - 561s 3s/step - loss: 1.0209 - accuracy: 0.5775 - val_loss: 1.1807 - val_accuracy: 0.4777 - lr: 1.0000e-06\n"]}],"source":["# 모델 훈련\n","history = model.fit(\n","    train_generator,\n","    epochs=100,\n","    validation_data=validation_generator,\n","    callbacks=[reduce_lr, early_stopping],\n","    class_weight=class_weights\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"collapsed":true,"id":"IYiJIHEuMmcM","outputId":"fd876cea-894c-4ae9-bfbd-30ea7a109c8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," mobilenet_1.00_224 (Functi  (None, 7, 7, 1024)        3228864   \n"," onal)                                                           \n","                                                                 \n"," gap (GlobalAveragePooling2  (None, 1024)              0         \n"," D)                                                              \n","                                                                 \n"," dense_1 (Dense)             (None, 4)                 4100      \n","                                                                 \n","=================================================================\n","Total params: 3232964 (12.33 MB)\n","Trainable params: 3197316 (12.20 MB)\n","Non-trainable params: 35648 (139.25 KB)\n","_________________________________________________________________\n"]}],"source":["# 파인튜닝 과정\n","base_model = model.layers[1]\n","base_model.trainable = True\n","\n","num_freeze_layers = 18\n","\n","# 하위 레이어 고정, 상위 레이어 해제\n","for layer in base_model.layers[:num_freeze_layers]:\n","    layer.trainable = False\n","for layer in base_model.layers[num_freeze_layers:]:\n","    layer.trainable = True\n","\n","# 모델 재컴파일\n","model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":534487,"status":"ok","timestamp":1716376325410,"user":{"displayName":"박태우","userId":"12492517778931241346"},"user_tz":-540},"id":"qG5UtjAI11_K"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","183/183 [==============================] - 574s 3s/step - loss: 1.1080 - accuracy: 0.5279 - val_loss: 1.0995 - val_accuracy: 0.5300 - lr: 1.0000e-04\n","Epoch 2/100\n","183/183 [==============================] - 561s 3s/step - loss: 0.8074 - accuracy: 0.6709 - val_loss: 0.8220 - val_accuracy: 0.6438 - lr: 1.0000e-04\n","Epoch 3/100\n","183/183 [==============================] - 555s 3s/step - loss: 0.6759 - accuracy: 0.7321 - val_loss: 0.7131 - val_accuracy: 0.7046 - lr: 1.0000e-04\n","Epoch 4/100\n","183/183 [==============================] - 549s 3s/step - loss: 0.6035 - accuracy: 0.7588 - val_loss: 0.7022 - val_accuracy: 0.7235 - lr: 1.0000e-04\n","Epoch 5/100\n","183/183 [==============================] - 549s 3s/step - loss: 0.5632 - accuracy: 0.7808 - val_loss: 0.6232 - val_accuracy: 0.7526 - lr: 1.0000e-04\n","Epoch 6/100\n","183/183 [==============================] - 548s 3s/step - loss: 0.5044 - accuracy: 0.8056 - val_loss: 0.6360 - val_accuracy: 0.7423 - lr: 1.0000e-04\n","Epoch 7/100\n","183/183 [==============================] - 550s 3s/step - loss: 0.4908 - accuracy: 0.8073 - val_loss: 0.6216 - val_accuracy: 0.7586 - lr: 1.0000e-04\n","Epoch 8/100\n","183/183 [==============================] - 566s 3s/step - loss: 0.4458 - accuracy: 0.8339 - val_loss: 0.7330 - val_accuracy: 0.7243 - lr: 1.0000e-04\n","Epoch 9/100\n","183/183 [==============================] - 554s 3s/step - loss: 0.4515 - accuracy: 0.8290 - val_loss: 0.6851 - val_accuracy: 0.7586 - lr: 1.0000e-04\n","Epoch 10/100\n","183/183 [==============================] - 550s 3s/step - loss: 0.3274 - accuracy: 0.8761 - val_loss: 0.6103 - val_accuracy: 0.7765 - lr: 1.0000e-05\n","Epoch 11/100\n","183/183 [==============================] - 546s 3s/step - loss: 0.2990 - accuracy: 0.8872 - val_loss: 0.6513 - val_accuracy: 0.7714 - lr: 1.0000e-05\n","Epoch 12/100\n","183/183 [==============================] - 552s 3s/step - loss: 0.2892 - accuracy: 0.8958 - val_loss: 0.6393 - val_accuracy: 0.7783 - lr: 1.0000e-05\n","Epoch 13/100\n","183/183 [==============================] - 554s 3s/step - loss: 0.2786 - accuracy: 0.8939 - val_loss: 0.6240 - val_accuracy: 0.7808 - lr: 1.0000e-06\n","Epoch 14/100\n","183/183 [==============================] - 572s 3s/step - loss: 0.2801 - accuracy: 0.8973 - val_loss: 0.6204 - val_accuracy: 0.7825 - lr: 1.0000e-06\n","Epoch 15/100\n","183/183 [==============================] - 614s 3s/step - loss: 0.2737 - accuracy: 0.9014 - val_loss: 0.6252 - val_accuracy: 0.7825 - lr: 1.0000e-06\n","Epoch 16/100\n","183/183 [==============================] - 603s 3s/step - loss: 0.2786 - accuracy: 0.8942 - val_loss: 0.6220 - val_accuracy: 0.7808 - lr: 1.0000e-06\n","Epoch 17/100\n","183/183 [==============================] - 555s 3s/step - loss: 0.2730 - accuracy: 0.8980 - val_loss: 0.6233 - val_accuracy: 0.7825 - lr: 1.0000e-07\n","Epoch 18/100\n","183/183 [==============================] - 551s 3s/step - loss: 0.2744 - accuracy: 0.9004 - val_loss: 0.6252 - val_accuracy: 0.7842 - lr: 1.0000e-07\n","Epoch 19/100\n","183/183 [==============================] - 569s 3s/step - loss: 0.2787 - accuracy: 0.8960 - val_loss: 0.6256 - val_accuracy: 0.7834 - lr: 1.0000e-07\n"]}],"source":["# 모델 학습\n","history_fine = model.fit(\n","    train_generator,\n","    epochs=100,\n","    validation_data=validation_generator,\n","    class_weight=class_weights,\n","    callbacks=[reduce_lr, early_stopping]\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":457,"status":"ok","timestamp":1716376325866,"user":{"displayName":"박태우","userId":"12492517778931241346"},"user_tz":-540},"id":"gu7AzcLndjh3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["# 모델 저장\n","model.save('/content/drive/MyDrive/MobileNetV1_01-05.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"sB5d2u6qsafF"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","\n","# 모델 파일 경로\n","model_path = '/content/drive/MyDrive/MobileNetV1_01-05.h5'\n","\n","# 모델 로드\n","model = load_model(model_path)\n","\n","# 테스트 데이터 디렉토리 경로\n","test_data_dir = '/content/drive/MyDrive/Data/img/test'\n","\n","# 테스트 데이터를 위한 ImageDataGenerator 생성\n","val_test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# 테스트 데이터 생성기 생성\n","test_generator = val_test_datagen.flow_from_directory(\n","    test_data_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    shuffle=False\n",")\n","\n","# 테스트 데이터 전체 검증\n","test_loss, test_accuracy = model.evaluate(test_generator)\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")\n","\n","# 예측 값 얻기\n","predictions = model.predict(test_generator)\n","predicted_classes = np.argmax(predictions, axis=1)\n","true_classes = test_generator.classes\n","class_labels = list(test_generator.class_indices.keys())\n","\n","# 각 클래스별 정확도 계산 및 잘못 예측한 경우 정리\n","misclassified_summary = []\n","\n","for i, label in enumerate(class_labels):\n","    indices = np.where(true_classes == i)[0]\n","    class_accuracy = accuracy_score(true_classes[indices], predicted_classes[indices])\n","    print(f\"Accuracy for class {label}: {class_accuracy * 100:.2f}%\")\n","\n","    # 잘못 예측한 경우 저장\n","    misclassified_indices = indices[true_classes[indices] != predicted_classes[indices]]\n","    for index in misclassified_indices:\n","        true_label = class_labels[true_classes[index]]\n","        predicted_label = class_labels[predicted_classes[index]]\n","        misclassified_summary.append((true_label, predicted_label))\n","\n","# DataFrame으로 정리\n","misclassified_df = pd.DataFrame(misclassified_summary, columns=[\"True Label\", \"Predicted Label\"])\n","\n","# 잘못 예측한 경우를 집계\n","misclassified_counts = misclassified_df.groupby(['True Label', 'Predicted Label']).size().reset_index(name='Count')\n","\n","# 정리된 결과 출력\n","print(\"\\nMisclassified Cases Summary:\")\n","print(misclassified_counts)\n"]},{"cell_type":"markdown","metadata":{"id":"p5kkjYL9WQnh"},"source":["#Sub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcSMwp53SmTv"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","\n","# 이미지 전처리 함수\n","def load_and_prepare_image(image_path, target_size=(224, 224)):\n","    img = image.load_img(image_path, target_size=target_size)\n","    img_tensor = image.img_to_array(img)\n","    img_tensor = np.expand_dims(img_tensor, axis=0)\n","    img_tensor /= 255.0  # 정규화\n","    return img_tensor\n","\n","# 감정을 예측하는 함수\n","def predict_emotion(model, img_path):\n","    print(\"이미지 로딩 중...\")\n","    test_image = load_and_prepare_image(img_path)\n","    print(\"감정 예측 중...\")\n","    prediction = model.predict(test_image)\n","    return prediction\n","\n","# 모델 경로와 이미지 경로\n","model_path = '/content/drive/MyDrive/MobileNetV1_01-04.h5'  # 학습된 모델 경로\n","image_path = '/content/drive/MyDrive/testimg/5.jpg'  # 테스트할 이미지 경로\n","\n","# 모델 로드\n","model = load_model(model_path)\n","\n","# 예측 결과 얻기\n","predictions = predict_emotion(model, image_path)\n","emotion_index = np.argmax(predictions)\n","emotion_labels = ['화남', '행복', '슬픔', '충격']  # 실제 감정 레이블로 변경\n","\n","print(\"예측된 감정:\", emotion_labels[emotion_index])\n","print(\"각 감정의 비율:\")\n","for i, label in enumerate(emotion_labels):\n","    print(f\"{label}: {predictions[0][i] * 100:.2f}%\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}