{"cells":[{"cell_type":"code","execution_count":1,"id":"afba9042","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-05T03:08:04.363918Z","iopub.status.busy":"2024-04-05T03:08:04.359563Z","iopub.status.idle":"2024-04-05T03:08:09.251117Z","shell.execute_reply":"2024-04-05T03:08:09.250372Z","shell.execute_reply.started":"2024-04-05T03:06:26.029431Z"},"papermill":{"duration":4.906285,"end_time":"2024-04-05T03:08:09.251280","exception":false,"start_time":"2024-04-05T03:08:04.344995","status":"completed"},"tags":[],"id":"afba9042","executionInfo":{"status":"ok","timestamp":1716039384017,"user_tz":-540,"elapsed":4684,"user":{"displayName":"이스트캠퍼스","userId":"11506478735001745454"}}},"outputs":[],"source":["import h5py\n","import datetime\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.utils import shuffle\n","from sklearn.utils.class_weight import compute_class_weight\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"id":"bfe0490b","metadata":{"execution":{"iopub.execute_input":"2024-04-05T03:08:09.268693Z","iopub.status.busy":"2024-04-05T03:08:09.267799Z","iopub.status.idle":"2024-04-05T03:08:09.270493Z","shell.execute_reply":"2024-04-05T03:08:09.269879Z","shell.execute_reply.started":"2024-04-05T03:06:31.268251Z"},"papermill":{"duration":0.013423,"end_time":"2024-04-05T03:08:09.270616","exception":false,"start_time":"2024-04-05T03:08:09.257193","status":"completed"},"tags":[],"id":"bfe0490b","executionInfo":{"status":"ok","timestamp":1716039386770,"user_tz":-540,"elapsed":386,"user":{"displayName":"이스트캠퍼스","userId":"11506478735001745454"}}},"outputs":[],"source":["NUM_CLASSES = 8\n","IMG_SHAPE = (120, 120, 3)\n","BATCH_SIZE = 8\n","\n","TRAIN_EPOCH = 100\n","TRAIN_LR = 1e-3\n","TRAIN_ES_PATIENCE = 5\n","TRAIN_LR_PATIENCE = 3\n","TRAIN_MIN_LR = 1e-6\n","TRAIN_DROPOUT = 0.1\n","\n","FT_EPOCH = 500\n","FT_LR = 1e-5\n","FT_LR_DECAY_STEP = 80.0\n","FT_LR_DECAY_RATE = 1\n","FT_ES_PATIENCE = 20\n","FT_DROPOUT = 0.2\n","\n","ES_LR_MIN_DELTA = 0.003"]},{"cell_type":"code","execution_count":null,"id":"d318d802","metadata":{"execution":{"iopub.execute_input":"2024-04-05T03:08:09.298321Z","iopub.status.busy":"2024-04-05T03:08:09.297711Z","iopub.status.idle":"2024-04-05T03:08:21.833062Z","shell.execute_reply":"2024-04-05T03:08:21.832391Z","shell.execute_reply.started":"2024-04-05T03:06:31.275621Z"},"papermill":{"duration":12.557677,"end_time":"2024-04-05T03:08:21.833202","exception":false,"start_time":"2024-04-05T03:08:09.275525","status":"completed"},"tags":[],"id":"d318d802"},"outputs":[],"source":["# Load your data here, PAtt-Lite was trained with h5py for shorter loading time\n","X_train, y_train = shuffle(X_train, y_train)\n","\n","print(\"Shape of train_sample: {}\".format(X_train.shape))\n","print(\"Shape of train_label: {}\".format(y_train.shape))\n","print(\"Shape of valid_sample: {}\".format(X_valid.shape))\n","print(\"Shape of valid_label: {}\".format(y_valid.shape))\n","print(\"Shape of test_sample: {}\".format(X_test.shape))\n","print(\"Shape of test_label: {}\".format(y_test.shape))\n","\n","class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n","class_weights = dict(enumerate(class_weights))"]},{"cell_type":"code","execution_count":10,"id":"e772bf90","metadata":{"execution":{"iopub.execute_input":"2024-04-05T03:08:21.872945Z","iopub.status.busy":"2024-04-05T03:08:21.872214Z","iopub.status.idle":"2024-04-05T04:11:01.037919Z","shell.execute_reply":"2024-04-05T04:11:01.038380Z","shell.execute_reply.started":"2024-04-05T03:06:43.580536Z"},"papermill":{"duration":3759.199616,"end_time":"2024-04-05T04:11:01.038616","exception":false,"start_time":"2024-04-05T03:08:21.839000","status":"completed"},"tags":[],"id":"e772bf90","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716039807489,"user_tz":-540,"elapsed":2300,"user":{"displayName":"이스트캠퍼스","userId":"11506478735001745454"}},"outputId":"0d79b27b-99b3-444c-acfe-f14a5da0b020"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"train-head\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," universal_input (InputLaye  [(None, 120, 120, 3)]        0         []                            \n"," r)                                                                                               \n","                                                                                                  \n"," resize (Resizing)           (None, 224, 224, 3)          0         ['universal_input[0][0]']     \n","                                                                                                  \n"," augmentation (Sequential)   (None, 224, 224, 3)          0         ['resize[0][0]']              \n","                                                                                                  \n"," tf.math.truediv_3 (TFOpLam  (None, 224, 224, 3)          0         ['augmentation[0][0]']        \n"," bda)                                                                                             \n","                                                                                                  \n"," tf.math.subtract_3 (TFOpLa  (None, 224, 224, 3)          0         ['tf.math.truediv_3[0][0]']   \n"," mbda)                                                                                            \n","                                                                                                  \n"," base_model (Functional)     (None, 14, 14, 512)          821952    ['tf.math.subtract_3[0][0]']  \n","                                                                                                  \n"," patch_extraction (Sequenti  (None, 2, 2, 256)            272128    ['base_model[0][0]']          \n"," al)                                                                                              \n","                                                                                                  \n"," gap (GlobalAveragePooling2  (None, 256)                  0         ['patch_extraction[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," dropout_5 (Dropout)         (None, 256)                  0         ['gap[0][0]']                 \n","                                                                                                  \n"," pre_classification (Sequen  (None, 32)                   8352      ['dropout_5[0][0]']           \n"," tial)                                                                                            \n","                                                                                                  \n"," attention (Attention)       (None, 32)                   1         ['pre_classification[0][0]',  \n","                                                                     'pre_classification[0][0]']  \n","                                                                                                  \n"," classification_head (Dense  (None, 8)                    264       ['attention[0][0]']           \n"," )                                                                                                \n","                                                                                                  \n","==================================================================================================\n","Total params: 1102697 (4.21 MB)\n","Trainable params: 280681 (1.07 MB)\n","Non-trainable params: 822016 (3.14 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["# Model Building\n","input_layer = tf.keras.Input(shape=IMG_SHAPE, name='universal_input')\n","sample_resizing = tf.keras.layers.experimental.preprocessing.Resizing(224, 224, name=\"resize\")\n","data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip(mode='horizontal'),\n","                                        tf.keras.layers.RandomContrast(factor=0.3)], name=\"augmentation\")\n","preprocess_input = tf.keras.applications.mobilenet.preprocess_input\n","\n","backbone = tf.keras.applications.mobilenet.MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n","backbone.trainable = False\n","base_model = tf.keras.Model(backbone.input, backbone.layers[-29].output, name='base_model')\n","\n","self_attention = tf.keras.layers.Attention(use_scale=True, name='attention')\n","patch_extraction = tf.keras.Sequential([\n","    tf.keras.layers.SeparableConv2D(256, kernel_size=4, strides=4, padding='same', activation='relu'),\n","    tf.keras.layers.SeparableConv2D(256, kernel_size=2, strides=2, padding='valid', activation='relu'),\n","    tf.keras.layers.Conv2D(256, kernel_size=1, strides=1, padding='valid', activation='relu')\n","], name='patch_extraction')\n","global_average_layer = tf.keras.layers.GlobalAveragePooling2D(name='gap')\n","pre_classification = tf.keras.Sequential([tf.keras.layers.Dense(32, activation='relu'),\n","                                          tf.keras.layers.BatchNormalization()], name='pre_classification')\n","prediction_layer = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name='classification_head')\n","\n","inputs = input_layer\n","x = sample_resizing(inputs)\n","x = data_augmentation(x)\n","x = preprocess_input(x)\n","x = base_model(x, training=False)\n","x = patch_extraction(x)\n","x = global_average_layer(x)\n","x = tf.keras.layers.Dropout(TRAIN_DROPOUT)(x)\n","x = pre_classification(x)\n","x = self_attention([x, x])\n","outputs = prediction_layer(x)\n","model = tf.keras.Model(inputs, outputs, name='train-head')\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=TRAIN_LR, global_clipnorm=3.0), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()\n"]},{"cell_type":"code","source":["num_layers = len(base_model.layers)\n","print(f\"Total number of layers in the base model: {num_layers}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBKz7Uqt8MLE","executionInfo":{"status":"ok","timestamp":1716039808689,"user_tz":-540,"elapsed":2,"user":{"displayName":"이스트캠퍼스","userId":"11506478735001745454"}},"outputId":"9c3d4612-76c9-419d-a719-460fb89adb60"},"id":"YBKz7Uqt8MLE","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of layers in the base model: 58\n"]}]},{"cell_type":"code","source":["# Training Procedure\n","early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=TRAIN_ES_PATIENCE, min_delta=ES_LR_MIN_DELTA, restore_best_weights=True)\n","learning_rate_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=TRAIN_LR_PATIENCE, verbose=0, min_delta=ES_LR_MIN_DELTA, min_lr=TRAIN_MIN_LR)\n","history = model.fit(X_train, y_train, epochs=TRAIN_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_valid, y_valid), verbose=0,\n","                    class_weight=class_weights, callbacks=[early_stopping_callback, learning_rate_callback])\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n"],"metadata":{"id":"rNlCKlPH6pWT"},"id":"rNlCKlPH6pWT","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model Finetuning\n","print(\"\\nFinetuning ...\")\n","unfreeze = 59\n","base_model.trainable = True\n","fine_tune_from = len(base_model.layers) - unfreeze\n","for layer in base_model.layers[:fine_tune_from]:\n","    layer.trainable = False\n","for layer in base_model.layers[fine_tune_from:]:\n","    if isinstance(layer, tf.keras.layers.BatchNormalization):\n","        layer.trainable = False\n","\n","inputs = input_layer\n","x = sample_resizing(inputs)\n","x = data_augmentation(x)\n","x = preprocess_input(x)\n","x = base_model(x, training=False)\n","x = patch_extraction(x)\n","x = tf.keras.layers.SpatialDropout2D(FT_DROPOUT)(x)\n","x = global_average_layer(x)\n","x = tf.keras.layers.Dropout(FT_DROPOUT)(x)\n","x = pre_classification(x)\n","x = self_attention([x, x])\n","x = tf.keras.layers.Dropout(FT_DROPOUT)(x)\n","outputs = prediction_layer(x)\n","model = tf.keras.Model(inputs, outputs, name='finetune-backbone')\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=FT_LR, global_clipnorm=3.0), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1zEB0kH6ooj","executionInfo":{"status":"ok","timestamp":1716039795421,"user_tz":-540,"elapsed":765,"user":{"displayName":"이스트캠퍼스","userId":"11506478735001745454"}},"outputId":"7dbffbc4-81d1-405b-cb28-15476ea5e314"},"id":"L1zEB0kH6ooj","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Finetuning ...\n","Model: \"finetune-backbone\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," universal_input (InputLaye  [(None, 120, 120, 3)]        0         []                            \n"," r)                                                                                               \n","                                                                                                  \n"," resize (Resizing)           (None, 224, 224, 3)          0         ['universal_input[0][0]']     \n","                                                                                                  \n"," augmentation (Sequential)   (None, 224, 224, 3)          0         ['resize[2][0]']              \n","                                                                                                  \n"," tf.math.truediv_2 (TFOpLam  (None, 224, 224, 3)          0         ['augmentation[2][0]']        \n"," bda)                                                                                             \n","                                                                                                  \n"," tf.math.subtract_2 (TFOpLa  (None, 224, 224, 3)          0         ['tf.math.truediv_2[0][0]']   \n"," mbda)                                                                                            \n","                                                                                                  \n"," base_model (Functional)     (None, 14, 14, 512)          821952    ['tf.math.subtract_2[0][0]']  \n","                                                                                                  \n"," patch_extraction (Sequenti  (None, 2, 2, 256)            272128    ['base_model[2][0]']          \n"," al)                                                                                              \n","                                                                                                  \n"," spatial_dropout2d_1 (Spati  (None, 2, 2, 256)            0         ['patch_extraction[2][0]']    \n"," alDropout2D)                                                                                     \n","                                                                                                  \n"," gap (GlobalAveragePooling2  (None, 256)                  0         ['spatial_dropout2d_1[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," dropout_3 (Dropout)         (None, 256)                  0         ['gap[2][0]']                 \n","                                                                                                  \n"," pre_classification (Sequen  (None, 32)                   8352      ['dropout_3[0][0]']           \n"," tial)                                                                                            \n","                                                                                                  \n"," attention (Attention)       (None, 32)                   1         ['pre_classification[2][0]',  \n","                                                                     'pre_classification[2][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)         (None, 32)                   0         ['attention[2][0]']           \n","                                                                                                  \n"," classification_head (Dense  (None, 8)                    264       ['dropout_4[0][0]']           \n"," )                                                                                                \n","                                                                                                  \n","==================================================================================================\n","Total params: 1102697 (4.21 MB)\n","Trainable params: 280681 (1.07 MB)\n","Non-trainable params: 822016 (3.14 MB)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["num_layers = len(model.layers)\n","print(f\"Total number of layers in the base model: {num_layers}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DiLbUXHj8SU8","executionInfo":{"status":"ok","timestamp":1716039798642,"user_tz":-540,"elapsed":2,"user":{"displayName":"이스트캠퍼스","userId":"11506478735001745454"}},"outputId":"a097f3a9-b739-499f-a020-80f4d36fb1ec"},"id":"DiLbUXHj8SU8","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of layers in the base model: 14\n"]}]},{"cell_type":"code","source":["# Training Procedure\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=ES_LR_MIN_DELTA, patience=FT_ES_PATIENCE, restore_best_weights=True)\n","scheduler = keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate=FT_LR, decay_steps=FT_LR_DECAY_STEP, decay_rate=FT_LR_DECAY_RATE)\n","scheduler_callback = tf.keras.callbacks.LearningRateScheduler(schedule=scheduler)\n","\n","history_finetune = model.fit(X_train, y_train, epochs=FT_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_valid, y_valid), verbose=0,\n","                             initial_epoch=history.epoch[-TRAIN_ES_PATIENCE], callbacks=[early_stopping_callback, scheduler_callback, tensorboard_callback])\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","model.save('model.h5')"],"metadata":{"id":"jeuJFzMs6qQY"},"id":"jeuJFzMs6qQY","execution_count":null,"outputs":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1718596,"sourceId":5546170,"sourceType":"datasetVersion"}],"dockerImageVersionId":30153,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"papermill":{"default_parameters":{},"duration":3788.698907,"end_time":"2024-04-05T04:11:04.022881","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-05T03:07:55.323974","version":"2.3.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}